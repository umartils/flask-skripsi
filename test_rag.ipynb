{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6bad9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from flask import Flask,g\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from module.db import Database\n",
    "from module.rag import RAGChatbot\n",
    "\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68522505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store directory 'vectorstore_chroma_db1' found.\n",
      "RAG chatbot initialized successfully.\n",
      "Loaded existing vectorstore with 283 documents\n"
     ]
    }
   ],
   "source": [
    "DATABASE_FILE = 'database.db'\n",
    "EMBEDDING_NAME = \"LazarusNLP/all-indobert-base-v2\"\n",
    "LLM_NAME = \"gemini-2.5-flash\"\n",
    "VECTOR_STORE_DIR = \"vectorstore_chroma_db1\"\n",
    "COLLECTION_NAME = \"grape_vector_store\"\n",
    "\n",
    "chatbot_model = ChatGoogleGenerativeAI(\n",
    "    model=LLM_NAME,\n",
    "    google_api_key=os.environ[\"GOOGLE_API_KEY\"]\n",
    ")\n",
    "\n",
    "if os.path.exists(VECTOR_STORE_DIR):\n",
    "    print(f\"Vector store directory '{VECTOR_STORE_DIR}' found.\")\n",
    "    try:\n",
    "        embedding_model = HuggingFaceEmbeddings(\n",
    "            model_name=EMBEDDING_NAME,\n",
    "            model_kwargs={\"device\": \"cuda\"},   # ubah ke \"cuda\" jika pakai GPU\n",
    "            encode_kwargs={'normalize_embeddings': True}\n",
    "        )\n",
    "\n",
    "        vector_store = Chroma(\n",
    "            persist_directory=VECTOR_STORE_DIR,\n",
    "            embedding_function=embedding_model,\n",
    "            collection_name=COLLECTION_NAME\n",
    "        )\n",
    "\n",
    "        rag_chatbot = RAGChatbot(chatbot_model, vector_store)\n",
    "        print(\"RAG chatbot initialized successfully.\")\n",
    "        print(f\"Loaded existing vectorstore with {vector_store._collection.count()} documents\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing RAG chatbot: {e}\")\n",
    "        rag_chatbot = None\n",
    "else:\n",
    "    print(f\"Vector store directory '{VECTOR_STORE_DIR}' not found. RAG chatbot will not be available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c15bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app = Flask(__name__)\n",
    "\n",
    "# def get_db():\n",
    "#     \"\"\"\n",
    "#     Membuka koneksi database baru jika belum ada untuk request saat ini.\n",
    "#     \"\"\"\n",
    "#     if 'db' not in g:\n",
    "#         g.db = Database(DATABASE_FILE)\n",
    "#         g.db.init_db() # Pastikan tabel ada\n",
    "#     return g.db\n",
    "\n",
    "# @app.teardown_appcontext\n",
    "# def close_db(e=None):\n",
    "#     \"\"\"\n",
    "#     Menutup koneksi database secara otomatis setelah request selesai.\n",
    "#     \"\"\"\n",
    "#     db = g.pop('db', None)\n",
    "#     if db is not None:\n",
    "#         db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e773c339",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RAGChatbot.hybrid_search() missing 1 required positional argument: 'chat_history'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m user_question = \u001b[33m\"\u001b[39m\u001b[33mApa penyakit yang disebabkan oleh jamur Cercospora spp. pada tanaman anggur?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m jawab = \u001b[43mrag_chatbot\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhybrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_question\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: RAGChatbot.hybrid_search() missing 1 required positional argument: 'chat_history'"
     ]
    }
   ],
   "source": [
    "user_question = \"Apa penyakit yang disebabkan oleh jamur Cercospora spp. pada tanaman anggur?\"\n",
    "jawab = rag_chatbot.hybrid_search(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "772eb7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cu128\n",
      "CUDA available: True\n",
      "CUDA version: 12.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747fce78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "klien-yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
